#!/usr/bin/env python3
"""
Objective-C í—¤ë” ì‹ë³„ì ì¶”ì¶œê¸° (ê°œì„ ëœ ìµœì¢…íŒ + SPM ì§€ì› + ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­)

ê³µê°œ API (ë‚œë…í™” ì œì™¸ ëŒ€ìƒ) ì‹ë³„ìë¥¼ 100% ì •í™•í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
í”„ë¡œì íŠ¸ ë‚´ë¶€ + DerivedDataì˜ SPM íŒ¨í‚¤ì§€ í—¤ë”ë„ ìŠ¤ìº”í•©ë‹ˆë‹¤.
"""

import re
import json
import argparse
import glob
from pathlib import Path
from typing import Set, Dict, List
from collections import defaultdict
from enum import Enum, auto


class ParseState(Enum):
    NORMAL = auto()
    SINGLE_LINE_COMMENT = auto()
    MULTI_LINE_COMMENT = auto()
    STRING = auto()
    STRING_ESCAPE = auto()
    PREPROCESSOR = auto()


class ObjectiveCCommentRemover:
    def remove_comments(self, source: str) -> str:
        result = []
        state = ParseState.NORMAL
        i = 0
        length = len(source)

        while i < length:
            char = source[i]

            if state == ParseState.NORMAL:
                if char == '/' and i + 1 < length:
                    if source[i + 1] == '/':
                        state = ParseState.SINGLE_LINE_COMMENT
                        i += 1
                    elif source[i + 1] == '*':
                        state = ParseState.MULTI_LINE_COMMENT
                        i += 1
                    else:
                        result.append(char)
                elif char == '"' or (char == '@' and i + 1 < length and source[i + 1] == '"'):
                    result.append(char)
                    if char == '@':
                        result.append('"')
                        i += 1
                    state = ParseState.STRING
                elif char == '#' and (i == 0 or source[i - 1] == '\n'):
                    result.append(char)
                    state = ParseState.PREPROCESSOR
                else:
                    result.append(char)

            elif state == ParseState.STRING:
                result.append(char)
                if char == '\\':
                    state = ParseState.STRING_ESCAPE
                elif char == '"':
                    state = ParseState.NORMAL

            elif state == ParseState.STRING_ESCAPE:
                result.append(char)
                state = ParseState.STRING

            elif state == ParseState.SINGLE_LINE_COMMENT:
                if char == '\n':
                    result.append(char)
                    state = ParseState.NORMAL

            elif state == ParseState.MULTI_LINE_COMMENT:
                if char == '*' and i + 1 < length and source[i + 1] == '/':
                    i += 1
                    state = ParseState.NORMAL

            elif state == ParseState.PREPROCESSOR:
                result.append(char)
                if char == '\n':
                    if len(result) >= 2 and result[-2] == '\\':
                        pass
                    else:
                        state = ParseState.NORMAL

            i += 1

        return "".join(result)


class ObjCHeaderParser:
    """ì™„ë²½ ìµœì¢…íŒ - Swift-generated í—¤ë” ì™„ë²½ ì§€ì›"""

    PATTERNS = {
        'interface': re.compile(r'@interface\s+(\w+)\s*[:(]', re.MULTILINE),
        'protocol': re.compile(r'@protocol\s+(\w+)\b', re.MULTILINE),

        'struct_typedef': re.compile(r'typedef\s+struct\s+\w*\s*\{[^}]*\}\s*(\w+)\s*;',
                                     re.MULTILINE | re.DOTALL),
        'struct_plain': re.compile(r'struct\s+(\w+)\s*\{', re.MULTILINE),

        'enum_ns': re.compile(r'(?:NS_ENUM|NS_OPTIONS|NS_CLOSED_ENUM|NS_ERROR_ENUM)\s*\(\s*\w+\s*,\s*(\w+)\s*\)',
                              re.MULTILINE),
        'enum_typedef': re.compile(r'typedef\s+enum\s+\w*\s*(?::\s*\w+)?\s*\{[^}]*\}\s*(\w+)\s*;',
                                   re.MULTILINE | re.DOTALL),
        'enum_forward_decl': re.compile(r'enum\s+(\w+)\s*:\s*\w+\s*;', re.MULTILINE),
        'swift_enum': re.compile(r'typedef\s+SWIFT_ENUM\s*\([^,]+,\s*(\w+)\s*,', re.MULTILINE),

        'typedef_funcptr': re.compile(r'typedef\s+.+\(\s*\*\s*(\w+)\s*\)\s*\(.*\)\s*;', re.MULTILINE),
        'typedef_block': re.compile(r'typedef\s+.+\(\s*\^\s*(\w+)\s*\)\s*\(.*\)\s*;', re.MULTILINE),
        'typedef': re.compile(r'typedef\s+(?!enum|struct|union).*?\s+(\w+)\s*;',
                              re.MULTILINE | re.DOTALL),

        'function': re.compile(r'^(?:extern\s+)?(?:static\s+)?(?:inline\s+)?[A-Z]\w*\s+\*?\s*(\w+)\s*\(',
                               re.MULTILINE),
        'export_function': re.compile(
            r'^(?:FOUNDATION_EXPORT|NS_SWIFT_NAME|UIKIT_EXTERN|extern)\s+.*?\*?\s*([a-zA-Z_]\w+)\s*\(',
            re.MULTILINE),

        'extern_const': re.compile(
            r'(?:FOUNDATION_EXPORT|UIKIT_EXTERN|extern)\s+(?:const\s+)?[\w\s\*]+?(?:const\s+)?(\w+)\s*;',
            re.MULTILINE),
        'extern_const_array': re.compile(
            r'(?:FOUNDATION_EXPORT|UIKIT_EXTERN|extern)\s+(?:const\s+)?[\w\s\*]+\s+(\w+)\s*\[\s*\]',
            re.MULTILINE),

        'macro_k_constant': re.compile(r'\b(k[A-Z]\w+)\b', re.MULTILINE),
    }

    @classmethod
    def parse(cls, file_path: Path) -> Dict[str, Set[str]]:
        result = defaultdict(set)

        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            remover = ObjectiveCCommentRemover()
            clean_content = remover.remove_comments(content)

            # ê¸°ë³¸ íŒ¨í„´ë“¤
            result['classes'].update(cls.PATTERNS['interface'].findall(clean_content))
            result['protocols'].update(cls.PATTERNS['protocol'].findall(clean_content))
            result['structs'].update(cls.PATTERNS['struct_typedef'].findall(clean_content))
            result['structs'].update(cls.PATTERNS['struct_plain'].findall(clean_content))

            result['enums'].update(cls.PATTERNS['enum_ns'].findall(clean_content))
            result['enums'].update(cls.PATTERNS['enum_typedef'].findall(clean_content))
            result['enums'].update(cls.PATTERNS['enum_forward_decl'].findall(clean_content))
            result['enums'].update(cls.PATTERNS['swift_enum'].findall(clean_content))

            result['typedefs'].update(cls.PATTERNS['typedef'].findall(clean_content))
            result['typedefs'].update(cls.PATTERNS['typedef_funcptr'].findall(clean_content))
            result['typedefs'].update(cls.PATTERNS['typedef_block'].findall(clean_content))

            result['functions'].update(cls.PATTERNS['function'].findall(clean_content))
            result['functions'].update(cls.PATTERNS['export_function'].findall(clean_content))

            result['constants'].update(cls.PATTERNS['extern_const'].findall(clean_content))
            result['constants'].update(cls.PATTERNS['extern_const_array'].findall(clean_content))
            result['constants'].update(cls.PATTERNS['macro_k_constant'].findall(clean_content))

            result['macros'].update(cls._extract_macros(content))

            # ë³µì¡í•œ íŒ¨í„´ë“¤
            result['enum_cases'].update(cls._extract_enum_cases(clean_content))
            result['methods'].update(cls._extract_methods(clean_content))
            result['properties'].update(cls._extract_properties(clean_content))

            # ì¹´í…Œê³ ë¦¬ ì œì™¸
            categories = cls._extract_categories(clean_content)
            for key in result:
                result[key] -= categories

            # í•„í„°ë§
            for key in result:
                result[key] = cls._filter_identifiers(result[key], key)

        except Exception as e:
            pass

        return dict(result)

    @classmethod
    def _extract_macros(cls, content: str) -> Set[str]:
        """#define ë§¤í¬ë¡œ ì¶”ì¶œ (ifndef/define í¬í•¨)"""
        macros = set()

        for line in content.split('\n'):
            line = line.strip()

            if line.startswith('//') or line.startswith('/*'):
                continue

            # #ifndef, #define ë‘˜ ë‹¤ ë§¤í¬ë¡œ ì´ë¦„
            if line.startswith('#ifndef') or line.startswith('#define'):
                match = re.match(r'^#(?:ifndef|define)\s+([A-Za-z_]\w*)(?:\s|$|\()', line)
                if match:
                    macro_name = match.group(1)
                    if len(macro_name) > 1:
                        macros.add(macro_name)

        return macros

    @classmethod
    def _extract_categories(cls, content: str) -> Set[str]:
        pattern = re.compile(r'@interface\s+\w+\s*\((\w+)\)', re.MULTILINE)
        return set(pattern.findall(content))

    @classmethod
    def _extract_enum_cases(cls, content: str) -> Set[str]:
        """enum case ê°’ë“¤ ì¶”ì¶œ"""
        cases = set()

        # #define ë¼ì¸ ì œê±°
        lines = []
        for line in content.split('\n'):
            if not line.strip().startswith('#define'):
                lines.append(line)
        clean_content = '\n'.join(lines)

        # enum ë¸”ë¡ë“¤ ì°¾ê¸°
        ns_enum_blocks = re.findall(
            r'(?:NS_ENUM|NS_OPTIONS|NS_CLOSED_ENUM|NS_ERROR_ENUM)\s*\([^)]+\)\s*\{([^}]+)\}',
            clean_content, re.DOTALL
        )

        typedef_enum_blocks = re.findall(
            r'typedef\s+enum[^{]*\{([^}]+)\}',
            clean_content, re.DOTALL
        )

        swift_enum_blocks = re.findall(
            r'typedef\s+SWIFT_ENUM\s*\([^)]+\)\s*\{([^}]+)\}',
            clean_content, re.DOTALL
        )

        all_blocks = ns_enum_blocks + typedef_enum_blocks + swift_enum_blocks

        for block in all_blocks:
            for line in block.split(','):
                line = line.strip()
                if not line:
                    continue

                match = re.match(r'^\s*([A-Za-z_]\w*)', line)
                if match:
                    case_name = match.group(1)
                    cases.add(case_name)

        return cases

    @classmethod
    def _extract_methods(cls, content: str) -> Set[str]:
        """Objective-C ë©”ì„œë“œ ì¶”ì¶œ"""
        methods = set()
        method_pattern = re.compile(r'^\s*[-+]\s*\((?:.+?)\)(.*?);', re.MULTILINE)
        block_pattern = re.compile(r'@(?:interface|protocol).*?@end', re.DOTALL)

        for block in block_pattern.findall(content):
            for match in method_pattern.finditer(block):
                method_sig = match.group(1).strip()

                # ì†ì„± ì œê±°
                method_sig = re.sub(r'\s+__attribute__\s*\(.*?\)', '', method_sig)
                method_sig = re.sub(r'\s+SWIFT_\w+(?:\([^)]*\))?', '', method_sig)
                method_sig = re.sub(r'\s+NS_\w+(?:\([^)]*\))?', '', method_sig)

                if ':' not in method_sig:
                    # íŒŒë¼ë¯¸í„° ì—†ëŠ” ë©”ì„œë“œ
                    selector = method_sig.strip()
                    if selector and re.match(r'^[a-zA-Z_]\w*$', selector):
                        methods.add(selector)
                else:
                    # íŒŒë¼ë¯¸í„° ìˆëŠ” ë©”ì„œë“œ
                    labels = re.findall(r'(\w+)\s*:', method_sig)
                    if labels:
                        selector = ':'.join(labels) + ':'
                        methods.add(selector)

        return methods

    @classmethod
    def _extract_properties(cls, content: str) -> Set[str]:
        """âœ… ì™„ë²½ ê°œì„ : @property + SWIFT_CLASS_PROPERTY + getter/setter ëª¨ë‘ ì¶”ì¶œ"""
        properties = set()

        # 1. ì¼ë°˜ @property íŒ¨í„´: @property (attrs) Type * name;
        prop_pattern = re.compile(r'@property\s*\(([^)]*)\)\s*[^;]+?\b(\w+)\s*;', re.MULTILINE | re.DOTALL)

        for match in prop_pattern.finditer(content):
            attributes = match.group(1)
            prop_name = match.group(2)
            if not prop_name or len(prop_name) <= 1: continue

            # getter ì¶”ì¶œ
            getter_match = re.search(r'getter\s*=\s*(\w+)', attributes)
            if getter_match:
                properties.add(getter_match.group(1))
            else:
                properties.add(prop_name)

            # setter ì¶”ì¶œ (readonlyê°€ ì•„ë‹ ë•Œ)
            if 'readonly' not in attributes:
                setter_match = re.search(r'setter\s*=\s*(\w+:)', attributes)
                if setter_match:
                    properties.add(setter_match.group(1))
                else:
                    setter = f"set{prop_name[0].upper()}{prop_name[1:]}:"
                    properties.add(setter)

        # 2. SWIFT_CLASS_PROPERTY íŒ¨í„´ ì¶”ê°€
        swift_class_prop_pattern = re.compile(
            r'SWIFT_CLASS_PROPERTY\s*\(\s*@property\s*\(([^)]*)\)\s*[^;]+?\b(\w+)\s*;\s*\)', re.MULTILINE | re.DOTALL)
        for match in swift_class_prop_pattern.finditer(content):
            attributes = match.group(1)
            prop_name = match.group(2)
            if not prop_name or len(prop_name) <= 1: continue

            # class propertyëŠ” getterë§Œ (ì£¼ë¡œ readonly)
            getter_match = re.search(r'getter\s*=\s*(\w+)', attributes)
            if getter_match:
                properties.add(getter_match.group(1))
            else:
                properties.add(prop_name)

        return properties

    @classmethod
    def _filter_identifiers(cls, identifiers: Set[str], id_type: str) -> Set[str]:
        """âœ… ìµœì¢… í•„í„°ë§: ë¶ˆí•„ìš”í•œ ë§¤í¬ë¡œ ë° ì‹œìŠ¤í…œ íƒ€ì… ì œê±° ê°•í™”"""
        SYSTEM_TYPES = {
            'NSInteger', 'NSUInteger', 'CGFloat', 'BOOL', 'id', 'void', 'int', 'float', 'double', 'char',
            'unsigned', 'signed', 'long', 'short', 'NSSecureCoding', 'NSCopying', 'NSCoding',
            'CFTimeInterval', 'NSTimeInterval', 'CGRect', 'CGPoint', 'CGSize', 'NSRange',
        }

        EXCLUDE_PATTERNS = [
            r'^API_DEPRECATED.*', r'^API_AVAILABLE.*',
            r'^NS_SWIFT_UI_ACTOR$', r'^NS_AVAILABLE.*', r'^NS_DEPRECATED.*',
            r'^NS_ENUM$', r'^NS_OPTIONS$', r'^NS_ERROR_ENUM$', r'^NS_CLOSED_ENUM$',
            r'^NS_DESIGNATED_INITIALIZER$', r'^UI_APPEARANCE_SELECTOR$',
            r'^OBJC_DESIGNATED_INITIALIZER$', r'^IB_DESIGNABLE$', r'^IBSegueAction$',
            r'^SWIFT_CLASS$', r'^SWIFT_PROTOCOL$', r'^SWIFT_ENUM$',
            r'^SWIFT_CLASS_PROPERTY$', r'^SWIFT_RESILIENT_CLASS$',
            r'^__\w+__$',
            r'^_Nonnull$', r'^_Nullable$', r'^_Null_unspecified$',
        ]

        filtered = set()
        for name in identifiers:
            if not name or len(name) <= 1: continue
            if not (name[0].isalpha() or name.startswith('_')): continue
            if name in SYSTEM_TYPES: continue
            if any(re.match(pattern, name) for pattern in EXCLUDE_PATTERNS): continue

            # ë§¤í¬ë¡œ íŒŒë¼ë¯¸í„° í˜•íƒœ ì œì™¸ (ì˜ˆ: _Val)
            if name.startswith('_') and not name.startswith('_Tt') and len(name) > 1 and name[1:].islower():
                continue

            filtered.add(name)
        return filtered


class HeaderScanner:
    def __init__(self, project_path: Path, exclude_dirs: List[str] = None, scan_spm: bool = True,
                 real_project_name: str = None):
        self.project_path = Path(project_path)
        self.exclude_dirs = exclude_dirs or [
            '.build', 'build', '.git', 'node_modules',
        ]
        self.scan_spm = scan_spm
        self.real_project_name = real_project_name
        self.header_results = {}
        self.stats = defaultdict(int)

    def should_skip_directory(self, dir_path: Path) -> bool:
        dir_name = dir_path.name
        if dir_name.startswith('.') and dir_name != '.':
            return True
        if dir_name in self.exclude_dirs:
            return True
        return False

    def find_header_files(self) -> List[Path]:
        """í”„ë¡œì íŠ¸ ë‚´ë¶€ í—¤ë” íŒŒì¼ ì°¾ê¸°"""
        header_files = []

        def scan_directory(directory: Path):
            try:
                for item in directory.iterdir():
                    if item.is_dir():
                        if not self.should_skip_directory(item):
                            scan_directory(item)
                    elif item.is_file() and item.suffix == '.h':
                        header_files.append(item)
            except PermissionError:
                pass

        scan_directory(self.project_path)
        return header_files

    def _normalize_project_name(self, name: str) -> List[str]:
        """í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì •ê·œí™”í•˜ì—¬ ê°€ëŠ¥í•œ ëª¨ë“  ë³€í˜• ìƒì„±"""
        variants = [name]

        # ê³µë°± â†’ ì–¸ë”ìŠ¤ì½”ì–´
        if ' ' in name:
            variants.append(name.replace(' ', '_'))

        # ì–¸ë”ìŠ¤ì½”ì–´ â†’ ê³µë°±
        if '_' in name:
            variants.append(name.replace('_', ' '))

        # í•˜ì´í”ˆ ë³€í˜•
        if ' ' in name:
            variants.append(name.replace(' ', '-'))
        if '_' in name:
            variants.append(name.replace('_', '-'))

        # ëŒ€ì†Œë¬¸ì ë³€í˜• (ì²« ê¸€ìë§Œ)
        if name[0].isupper():
            variants.append(name[0].lower() + name[1:])
        elif name[0].islower():
            variants.append(name[0].upper() + name[1:])

        return list(set(variants))  # ì¤‘ë³µ ì œê±°

    def find_spm_headers(self) -> List[Path]:
        """âœ… ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­: DerivedDataì˜ SPM íŒ¨í‚¤ì§€ í—¤ë” ì°¾ê¸°"""
        spm_headers = []

        # DerivedData ê¸°ë³¸ ê²½ë¡œ
        derived_data_base = Path.home() / "Library" / "Developer" / "Xcode" / "DerivedData"

        if not derived_data_base.exists():
            print(f"   âš ï¸  DerivedData í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {derived_data_base}")
            return spm_headers

        # 1. í”„ë¡œì íŠ¸ ì´ë¦„ ê²°ì •
        if self.real_project_name:
            project_name = self.real_project_name
            print(f"   â†’ ì§€ì •ëœ í”„ë¡œì íŠ¸ ì´ë¦„ '{project_name}' ì‚¬ìš©")
        else:
            project_name = self.project_path.name
            if project_name.endswith('.xcodeproj'):
                project_name = project_name[:-10]
            elif project_name.endswith('.xcworkspace'):
                project_name = project_name[:-12]
            print(f"   â†’ ì¶”ì¶œëœ í”„ë¡œì íŠ¸ ì´ë¦„ '{project_name}' ì‚¬ìš©")

        # 2. ëª¨ë“  ê°€ëŠ¥í•œ ë³€í˜• ìƒì„±
        name_variants = self._normalize_project_name(project_name)
        print(f"   â†’ ê²€ìƒ‰ ë³€í˜•: {', '.join(name_variants)}")

        # 3. ê° ë³€í˜•ìœ¼ë¡œ DerivedData ê²€ìƒ‰
        matching_dirs = []
        for variant in name_variants:
            pattern = f"{variant}-*"
            found = list(derived_data_base.glob(pattern))
            if found:
                matching_dirs.extend(found)
                print(f"   âœ“ '{pattern}' íŒ¨í„´ìœ¼ë¡œ {len(found)}ê°œ í´ë” ë°œê²¬")

        # 4. ì°¾ì§€ ëª»í–ˆì„ ë•Œ í´ë°±: ë¶€ë¶„ ë§¤ì¹­
        if not matching_dirs:
            print(f"   âš ï¸  ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨, ë¶€ë¶„ ë§¤ì¹­ ì‹œë„...")
            try:
                all_dirs = [d for d in derived_data_base.iterdir() if d.is_dir()]
                for variant in name_variants:
                    # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
                    variant_lower = variant.lower()
                    for d in all_dirs:
                        dir_name = d.name.split('-')[0].lower()  # í•´ì‹œ ë¶€ë¶„ ì œê±°
                        if variant_lower in dir_name or dir_name in variant_lower:
                            matching_dirs.append(d)
                            print(f"   âœ“ ë¶€ë¶„ ë§¤ì¹­: {d.name}")
            except Exception as e:
                pass

        # 5. ì—¬ì „íˆ ëª» ì°¾ì•˜ìœ¼ë©´ íŒíŠ¸ ì œê³µ
        if not matching_dirs:
            print(f"   âŒ DerivedDataì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ğŸ’¡ DerivedDataì— ìˆëŠ” í´ë” ëª©ë¡ (ìµœê·¼ 5ê°œ):")
            try:
                all_dirs = sorted(
                    [d for d in derived_data_base.iterdir() if d.is_dir()],
                    key=lambda x: x.stat().st_mtime,
                    reverse=True
                )
                for d in all_dirs[:5]:
                    print(f"      - {d.name}")
            except:
                pass
            return spm_headers

        # 6. SPM í—¤ë” ìˆ˜ì§‘
        print(f"\nğŸ“¦ SPM íŒ¨í‚¤ì§€ í—¤ë” ìŠ¤ìº” ì¤‘...")
        matching_dirs = list(set(matching_dirs))  # ì¤‘ë³µ ì œê±°

        for derived_dir in matching_dirs:
            checkouts_path = derived_dir / "SourcePackages" / "checkouts"

            if not checkouts_path.exists():
                print(f"   âš ï¸  SPM checkouts í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {derived_dir.name}")
                continue

            print(f"   â†’ ìŠ¤ìº”: {derived_dir.name}/SourcePackages/checkouts")

            # checkouts í´ë” ë‚´ì˜ ëª¨ë“  .h íŒŒì¼ ì¬ê·€ì ìœ¼ë¡œ ì°¾ê¸°
            for header_file in checkouts_path.rglob("*.h"):
                spm_headers.append(header_file)

        if spm_headers:
            print(f"   âœ… {len(spm_headers)}ê°œì˜ SPM í—¤ë” ë°œê²¬")
        else:
            print(f"   âš ï¸  SPM í—¤ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        return spm_headers

    def scan_all(self) -> Dict[str, Dict[str, Set[str]]]:
        print(f"ğŸ” í”„ë¡œì íŠ¸: {self.project_path}")
        print(f"ğŸ“‚ í—¤ë” íŒŒì¼ ê²€ìƒ‰ ì¤‘...\n")

        # 1. í”„ë¡œì íŠ¸ ë‚´ë¶€ í—¤ë”
        header_files = self.find_header_files()
        self.stats['project_headers'] = len(header_files)

        # 2. SPM íŒ¨í‚¤ì§€ í—¤ë”
        spm_headers = []
        if self.scan_spm:
            spm_headers = self.find_spm_headers()
            self.stats['spm_headers'] = len(spm_headers)

        # ì „ì²´ í—¤ë” ëª©ë¡
        all_headers = header_files + spm_headers
        self.stats['total_headers'] = len(all_headers)

        if not all_headers:
            print("âŒ í—¤ë” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        print(f"\nâœ“ ì´ {len(all_headers)}ê°œì˜ í—¤ë” íŒŒì¼ ë°œê²¬")
        print(f"  - í”„ë¡œì íŠ¸ ë‚´ë¶€: {len(header_files)}ê°œ")
        if self.scan_spm:
            print(f"  - SPM íŒ¨í‚¤ì§€: {len(spm_headers)}ê°œ")

        print("\nğŸ” ì‹ë³„ì ì¶”ì¶œ ì¤‘...")
        print("-" * 60)

        for header_file in all_headers:
            try:
                relative_path = str(header_file.relative_to(self.project_path))
            except ValueError:
                # SPM í—¤ë”ëŠ” ìƒëŒ€ ê²½ë¡œ ë¶ˆê°€ëŠ¥
                relative_path = f"[SPM] {header_file.name}"

            identifiers_by_type = ObjCHeaderParser.parse(header_file)
            total_count = sum(len(ids) for ids in identifiers_by_type.values())

            if total_count > 0:
                self.header_results[relative_path] = identifiers_by_type
                self.stats['success'] += 1
                print(f"âœ“ {relative_path}: {total_count}ê°œ")
            else:
                self.stats['failed'] += 1

        return self.header_results

    def get_all_identifiers_by_type(self) -> Dict[str, Set[str]]:
        merged = defaultdict(set)
        for header_data in self.header_results.values():
            for id_type, identifiers in header_data.items():
                merged[id_type].update(identifiers)
        return dict(merged)

    def get_all_identifiers(self) -> Set[str]:
        all_ids = set()
        for header_data in self.header_results.values():
            for identifiers in header_data.values():
                all_ids.update(identifiers)
        return all_ids

    def print_summary(self):
        print("\n" + "=" * 60)
        print("ğŸ“Š ì¶”ì¶œ ê²°ê³¼ ìš”ì•½ (ë‚œë…í™” ì œì™¸ ëŒ€ìƒ)")
        print("=" * 60)
        print(f"í”„ë¡œì íŠ¸ í—¤ë”:    {self.stats.get('project_headers', 0):>6}ê°œ")
        if self.scan_spm:
            print(f"SPM í—¤ë”:         {self.stats.get('spm_headers', 0):>6}ê°œ")
        print(f"ì´ í—¤ë” íŒŒì¼:     {self.stats['total_headers']:>6}ê°œ")
        print(f"ì„±ê³µ:            {self.stats['success']:>6}ê°œ")
        print(f"ì‹¤íŒ¨:            {self.stats['failed']:>6}ê°œ")

        merged = self.get_all_identifiers_by_type()
        print("\níƒ€ì…ë³„ ì‹ë³„ì ìˆ˜:")
        for id_type, identifiers in sorted(merged.items()):
            if identifiers:
                print(f"  {id_type:15s}: {len(identifiers):>6}ê°œ")

        total = len(self.get_all_identifiers())
        print(f"\nê³ ìœ  ì‹ë³„ì ì´í•©: {total:>6}ê°œ")
        print("=" * 60)

    def save_to_json(self, output_path: Path, include_per_header: bool = True):
        output_data = {
            "project_path": str(self.project_path),
            "description": "ë‚œë…í™”ì—ì„œ ì œì™¸í•´ì•¼ í•  ê³µê°œ API ì‹ë³„ì ëª©ë¡ (í”„ë¡œì íŠ¸ + SPM)",
            "project_headers": self.stats.get('project_headers', 0),
            "spm_headers": self.stats.get('spm_headers', 0),
            "total_headers": self.stats['total_headers'],
            "success": self.stats['success'],
            "failed": self.stats['failed'],
        }

        merged = self.get_all_identifiers_by_type()
        output_data["identifiers_by_type"] = {
            id_type: sorted(list(identifiers))
            for id_type, identifiers in merged.items()
        }

        all_ids = self.get_all_identifiers()
        output_data["all_identifiers"] = sorted(list(all_ids))
        output_data["total_identifiers"] = len(all_ids)

        if include_per_header:
            output_data["headers"] = {
                header_path: {
                    id_type: sorted(list(identifiers))
                    for id_type, identifiers in header_data.items()
                }
                for header_path, header_data in self.header_results.items()
            }

        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ JSON ì €ì¥: {output_path}")

    def save_to_txt(self, output_path: Path):
        all_ids = self.get_all_identifiers()
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            for identifier in sorted(all_ids):
                f.write(identifier + '\n')
        print(f"\nğŸ’¾ TXT ì €ì¥: {output_path} ({len(all_ids)}ê°œ)")


def main():
    parser = argparse.ArgumentParser(
        description="Objective-C í—¤ë”ì—ì„œ ê³µê°œ API ì‹ë³„ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (í”„ë¡œì íŠ¸ + SPM íŒ¨í‚¤ì§€)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument('project_path', type=Path, help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ')
    parser.add_argument('-o', '--output', type=Path, help='JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--txt', type=Path, help='TXT íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--exclude', nargs='+', help='ì œì™¸í•  ë””ë ‰í† ë¦¬')
    parser.add_argument('--no-per-header', action='store_true', help='í—¤ë”ë³„ ìƒì„¸ ì •ë³´ ì œì™¸')
    parser.add_argument('--no-spm', action='store_true', help='SPM íŒ¨í‚¤ì§€ ìŠ¤ìº” ë¹„í™œì„±í™”')
    parser.add_argument('--real-project-name', type=str, help='ë¹Œë“œ ì‹œ í™•ì¸ëœ ì‹¤ì œ í”„ë¡œì íŠ¸ ì´ë¦„ (DerivedData ê²€ìƒ‰ìš©)')

    args = parser.parse_args()

    if not args.project_path.exists():
        print(f"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.project_path}")
        return 1

    if not args.project_path.is_dir():
        print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {args.project_path}")
        return 1

    exclude_dirs = None
    if args.exclude:
        default_exclude = ['.build', 'build', '.git', 'node_modules']
        exclude_dirs = default_exclude + args.exclude

    print("ğŸš€ Objective-C í—¤ë” ì‹ë³„ì ì¶”ì¶œê¸°")
    print("   (ë‚œë…í™” ì œì™¸ ëŒ€ìƒ - ê³µê°œ API + SPM íŒ¨í‚¤ì§€)")
    print("=" * 60)
    print()

    scanner = HeaderScanner(
        args.project_path,
        exclude_dirs,
        scan_spm=not args.no_spm,
        real_project_name=args.real_project_name
    )
    scanner.scan_all()
    scanner.print_summary()

    if args.output:
        scanner.save_to_json(args.output, include_per_header=not args.no_per_header)

    if args.txt:
        scanner.save_to_txt(args.txt)

    print("\nâœ… ì™„ë£Œ!")
    print("ğŸ’¡ ì´ ì‹ë³„ìë“¤ì€ ê³µê°œ APIì´ë¯€ë¡œ ë‚œë…í™”ì—ì„œ ì œì™¸í•´ì•¼ í•©ë‹ˆë‹¤.")
    if not args.no_spm:
        print("ğŸ’¡ SPM íŒ¨í‚¤ì§€ì˜ í—¤ë”ë„ ìŠ¤ìº”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return 0


if __name__ == "__main__":
    exit(main())